import Foundation

/// AudioRecord SDK åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
@MainActor
class AudioRecordSDKExample {
    
    private let audioAPI = AudioAPI.shared
    private var currentStream: AudioStream?
    
    // MARK: - åŸºç¡€éº¦å…‹é£å½•åˆ¶
    
    func startMicrophoneRecording() async {
        do {
            // 1. åˆ›å»ºéº¦å…‹é£çº¦æŸ
            let constraints = createMicrophoneConstraints(
                echoCancellation: true,
                noiseSuppression: true
            )
            
            // 2. è·å–åª’ä½“æµ
            let stream = try await audioAPI.getUserMedia(constraints: constraints)
            currentStream = stream
            
            // 3. è®¾ç½®å›è°ƒ
            setupCallbacks()
            
            // 4. å¼€å§‹å½•åˆ¶
            try audioAPI.startRecording(stream: stream)
            
            print("âœ… éº¦å…‹é£å½•åˆ¶å·²å¼€å§‹")
            print("å½•åˆ¶æ¨¡å¼: \(stream.recordingMode)")
            print("è½¨é“æ•°é‡: \(stream.getAudioTracks().count)")
            
        } catch {
            print("âŒ éº¦å…‹é£å½•åˆ¶å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - æ··éŸ³å½•åˆ¶
    
    func startMixedRecording() async {
        do {
            // 1. åˆ›å»ºæ··éŸ³çº¦æŸ
            let constraints = createMixedAudioConstraints(
                echoCancellation: true,
                noiseSuppression: true
            )
            
            // 2. è·å–åª’ä½“æµ
            let stream = try await audioAPI.getUserMedia(constraints: constraints)
            currentStream = stream
            
            // 3. è®¾ç½®å›è°ƒ
            setupCallbacks()
            
            // 4. å¼€å§‹å½•åˆ¶
            try audioAPI.startRecording(stream: stream)
            
            print("âœ… æ··éŸ³å½•åˆ¶å·²å¼€å§‹ (éº¦å…‹é£ + ç³»ç»ŸéŸ³é¢‘)")
            print("å½•åˆ¶æ¨¡å¼: \(stream.recordingMode)")
            print("è½¨é“æ•°é‡: \(stream.getAudioTracks().count)")
            
        } catch {
            print("âŒ æ··éŸ³å½•åˆ¶å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - åœæ­¢å½•åˆ¶
    
    func stopRecording() {
        audioAPI.stopRecording()
        currentStream = nil
        print("ğŸ›‘ å½•åˆ¶å·²åœæ­¢")
    }
    
    // MARK: - è®¾ç½®å›è°ƒ
    
    private func setupCallbacks() {
        audioAPI.onLevel = { level in
            print("ğŸµ éŸ³é¢‘ç”µå¹³: \(String(format: "%.2f", level))")
        }
        
        audioAPI.onStatus = { status in
            print("ğŸ“Š çŠ¶æ€æ›´æ–°: \(status)")
        }
        
        audioAPI.onRecordingComplete = { recording in
            print("âœ… å½•åˆ¶å®Œæˆ:")
            print("  æ–‡ä»¶å: \(recording.fileName)")
            print("  æ—¶é•¿: \(recording.formattedDuration)")
            print("  å¤§å°: \(recording.formattedFileSize)")
            print("  è·¯å¾„: \(recording.fileURL.path)")
        }
    }
    
    // MARK: - æ£€æŸ¥çŠ¶æ€
    
    func checkRecordingStatus() {
        print("å½•åˆ¶çŠ¶æ€: \(audioAPI.isRecording ? "å½•åˆ¶ä¸­" : "æœªå½•åˆ¶")")
        
        if let stream = currentStream {
            print("æµçŠ¶æ€: \(stream.active ? "æ´»è·ƒ" : "éæ´»è·ƒ")")
            print("æµID: \(stream.id)")
            
            let tracks = stream.getAudioTracks()
            for (index, track) in tracks.enumerated() {
                print("è½¨é“ \(index + 1):")
                print("  ID: \(track.id)")
                print("  æ ‡ç­¾: \(track.label)")
                print("  å¯ç”¨: \(track.enabled)")
                print("  çŠ¶æ€: \(track.readyState)")
            }
        }
    }
}

// MARK: - ä½¿ç”¨ç¤ºä¾‹

/*
ä½¿ç”¨æ–¹æ³•:

let example = AudioRecordSDKExample()

// éº¦å…‹é£å½•åˆ¶
await example.startMicrophoneRecording()
await Task.sleep(nanoseconds: 5_000_000_000) // å½•åˆ¶ 5 ç§’
example.stopRecording()

// æ··éŸ³å½•åˆ¶
await example.startMixedRecording()
await Task.sleep(nanoseconds: 10_000_000_000) // å½•åˆ¶ 10 ç§’
example.stopRecording()

// æ£€æŸ¥çŠ¶æ€
example.checkRecordingStatus()

// æ‰“å° SDK ä¿¡æ¯
AudioRecordSDKInfo.printInfo()
*/
