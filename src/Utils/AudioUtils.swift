import Foundation
import AVFoundation
import Accelerate
import ScreenCaptureKit
import CoreAudio

/// éŸ³é¢‘å·¥å…·ç±»
class AudioUtils {
    static let shared = AudioUtils()
    
    private let logger = Logger.shared
    
    private init() {}
    
    /// éŸ³é¢‘æ ¼å¼æšä¸¾
    enum AudioFormat: String, CaseIterable {
        case m4a = "M4A"
        case wav = "WAV"
        
        var fileExtension: String {
            return rawValue.lowercased()
        }
        
        var settings: [String: Any] {
            switch self {
            case .m4a:
                return [
                    AVFormatIDKey: kAudioFormatMPEG4AAC,
                    AVSampleRateKey: 48000,
                    AVNumberOfChannelsKey: 2,
                    AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
                ]
            case .wav:
                return [
                    AVFormatIDKey: kAudioFormatLinearPCM,
                    AVSampleRateKey: 48000,
                    AVNumberOfChannelsKey: 2,
                    AVLinearPCMBitDepthKey: 16,
                    AVLinearPCMIsFloatKey: false,
                    AVLinearPCMIsBigEndianKey: false
                ]
            }
        }
        
        var displayName: String {
            return rawValue
        }
    }
    
    /// å½•éŸ³æ¨¡å¼æšä¸¾
    enum RecordingMode: String, CaseIterable {
        case microphone = "microphone"
        case specificProcess = "specificProcess"
        case systemMixdown = "systemMixdown"
        
        var displayName: String {
            switch self {
            case .microphone:
                return "éº¦å…‹é£"
            case .specificProcess:
                return "ç‰¹å®šè¿›ç¨‹"
            case .systemMixdown:
                return "ç³»ç»Ÿæ··éŸ³"
            }
        }
        
        var buttonTitle: String {
            switch self {
            case .microphone:
                return "å¼€å§‹å½•åˆ¶éº¦å…‹é£"
            case .specificProcess:
                return "å¼€å§‹å½•åˆ¶é€‰ä¸­è¿›ç¨‹"
            case .systemMixdown:
                return "å¼€å§‹å½•åˆ¶ç³»ç»Ÿæ··éŸ³"
            }
        }
    }
    
    /// è®¡ç®—éŸ³é¢‘ç”µå¹³ï¼ˆRMSï¼‰
    static func calculateAudioLevel(from buffer: AVAudioPCMBuffer) -> Float {
        guard let channelData = buffer.floatChannelData?[0] else { return 0.0 }
        
        let frameCount = Int(buffer.frameLength)
        var sum: Float = 0.0
        
        // ä½¿ç”¨ vDSP è®¡ç®— RMS
        vDSP_measqv(channelData, 1, &sum, vDSP_Length(frameCount))
        let rms = sqrtf(sum)
        
        // è½¬æ¢ä¸º dB
        let db = 20 * log10f(max(rms, 1e-6))
        
        // å½’ä¸€åŒ–åˆ° 0-1 èŒƒå›´ï¼ˆå‡è®¾ -60dB åˆ° 0dBï¼‰
        let normalized = max(0, min(1, (db + 60) / 60))
        
        return normalized
    }
    
    /// éªŒè¯éŸ³é¢‘æ–‡ä»¶
    func validateAudioFile(at url: URL) -> Bool {
        do {
            let audioFile = try AVAudioFile(forReading: url)
            let duration = Double(audioFile.length) / audioFile.fileFormat.sampleRate
            logger.info("éŸ³é¢‘æ–‡ä»¶éªŒè¯é€šè¿‡: \(url.lastPathComponent), æ—¶é•¿: \(String(format: "%.2f", duration))ç§’")
            return duration > 0
        } catch {
            logger.error("éŸ³é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥ \(url.lastPathComponent): \(error.localizedDescription)")
            return false
        }
    }
    
    /// è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
    func getAudioFileInfo(at url: URL) -> AudioFileInfo? {
        do {
            let audioFile = try AVAudioFile(forReading: url)
            let duration = Double(audioFile.length) / audioFile.fileFormat.sampleRate
            let sampleRate = audioFile.fileFormat.sampleRate
            let channels = audioFile.fileFormat.channelCount
            
            return AudioFileInfo(
                url: url,
                duration: duration,
                sampleRate: sampleRate,
                channels: channels,
                format: audioFile.fileFormat.commonFormat
            )
        } catch {
            logger.error("è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯å¤±è´¥ \(url.lastPathComponent): \(error.localizedDescription)")
            return nil
        }
    }
    
    /// æ£€æŸ¥éŸ³é¢‘æƒé™
    func checkAudioPermissions() -> (microphone: Bool, screenRecording: Bool) {
        // åœ¨macOSä¸Šï¼Œæˆ‘ä»¬é€šè¿‡å°è¯•åˆ›å»ºAVAudioEngineæ¥æ£€æŸ¥éº¦å…‹é£æƒé™
        let microphonePermission = checkMicrophonePermission()
        let screenRecordingPermission = checkScreenRecordingPermission()
        
        logger.info("éŸ³é¢‘æƒé™ - éº¦å…‹é£: \(microphonePermission), å±å¹•å½•åˆ¶: \(screenRecordingPermission)")
        
        return (microphonePermission, screenRecordingPermission)
    }
    
    /// æ£€æŸ¥å±å¹•å½•åˆ¶æƒé™
    private func checkScreenRecordingPermission() -> Bool {
        // é€šè¿‡å°è¯•è·å–å¯å…±äº«å†…å®¹æ¥æ£€æŸ¥å±å¹•å½•åˆ¶æƒé™
        var hasPermission = false
        let semaphore = DispatchSemaphore(value: 0)
        
        Task {
            do {
                let _ = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: true)
                hasPermission = true
            } catch {
                // æ£€æŸ¥æ˜¯å¦æ˜¯æƒé™é”™è¯¯
                if error.localizedDescription.contains("permission") || 
                   error.localizedDescription.contains("æƒé™") ||
                   error.localizedDescription.contains("denied") ||
                   error.localizedDescription.contains("not authorized") {
                    hasPermission = false
                } else {
                    // å…¶ä»–é”™è¯¯ï¼Œå¯èƒ½æƒé™æ˜¯æœ‰çš„
                    hasPermission = true
                }
            }
            semaphore.signal()
        }
        
        semaphore.wait()
        return hasPermission
    }
    
    /// è¯·æ±‚å±å¹•å½•åˆ¶æƒé™ï¼ˆé€šè¿‡å°è¯•è·å–å†…å®¹æ¥è§¦å‘ç³»ç»Ÿæƒé™å¯¹è¯æ¡†ï¼‰
    func requestScreenRecordingPermission(completion: @escaping (Bool) -> Void) {
        Task {
            do {
                let _ = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: true)
                DispatchQueue.main.async {
                    completion(true)
                }
            } catch {
                DispatchQueue.main.async {
                    completion(false)
                }
            }
        }
    }
    
    /// è·å–è¯¦ç»†çš„æƒé™çŠ¶æ€ä¿¡æ¯
    func getDetailedPermissionStatus() -> (microphone: Bool, screenRecording: Bool, systemVersion: String) {
        let microphonePermission = checkMicrophonePermission()
        let screenRecordingPermission = checkScreenRecordingPermission()
        let systemVersion = ProcessInfo.processInfo.operatingSystemVersionString
        
        return (microphonePermission, screenRecordingPermission, systemVersion)
    }
    
    /// æ£€æŸ¥éº¦å…‹é£æƒé™ï¼ˆmacOSæ–¹å¼ï¼‰
    private func checkMicrophonePermission() -> Bool {
        // åœ¨macOSä¸Šï¼Œæˆ‘ä»¬é€šè¿‡æ£€æŸ¥ç³»ç»Ÿæƒé™çŠ¶æ€æ¥éªŒè¯éº¦å…‹é£æƒé™
        let status = AVCaptureDevice.authorizationStatus(for: .audio)
        switch status {
        case .authorized:
            return true
        case .notDetermined, .denied, .restricted:
            return false
        @unknown default:
            return false
        }
    }
    
    /// è¯·æ±‚éº¦å…‹é£æƒé™
    func requestMicrophonePermission(completion: @escaping (Bool) -> Void) {
        let status = AVCaptureDevice.authorizationStatus(for: .audio)
        
        switch status {
        case .authorized:
            DispatchQueue.main.async {
                completion(true)
            }
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .audio) { granted in
                DispatchQueue.main.async {
                    completion(granted)
                }
            }
        case .denied, .restricted:
            DispatchQueue.main.async {
                completion(false)
            }
        @unknown default:
            DispatchQueue.main.async {
                completion(false)
            }
        }
    }
    
    // MARK: - éŸ³é¢‘æ•°æ®è½¬æ¢å·¥å…·
    
    /// è½¬æ¢32ä½æµ®ç‚¹æ•°æ®ä¸º16ä½æ•´æ•°æ•°æ®
    static func convertFloat32ToInt16(bufferList: AudioBufferList, frameCount: UInt32, inputChannels: Int, outputChannels: Int) throws -> Data {
        guard bufferList.mNumberBuffers == 1 else {
            throw AudioDataConversionError.unsupportedBufferCount(bufferList.mNumberBuffers)
        }
        
        let buffer = bufferList.mBuffers
        guard let srcData = buffer.mData else {
            throw AudioDataConversionError.emptyInputData
        }
        
        let frameCountInt = Int(frameCount)
        let totalSamples = Int(buffer.mDataByteSize) / MemoryLayout<Float>.size
        
        Logger.shared.info("ğŸ”„ æ•°æ®è½¬æ¢: è¾“å…¥å£°é“=\(inputChannels), è¾“å‡ºå£°é“=\(outputChannels), å¸§æ•°=\(frameCountInt)")
        
        // åˆ›å»ºè¾“å‡ºæ•°æ®ç¼“å†²åŒº
        let outputBytesPerFrame = outputChannels * MemoryLayout<Int16>.size
        let outputDataSize = frameCountInt * outputBytesPerFrame
        var outputData = Data(count: outputDataSize)
        
        let srcFloatData = srcData.assumingMemoryBound(to: Float.self)
        
        outputData.withUnsafeMutableBytes { outputBytes in
            let dstInt16Data = outputBytes.bindMemory(to: Int16.self)
            
            if inputChannels == 1 && outputChannels == 2 {
                // å•å£°é“è½¬ç«‹ä½“å£°
                for frame in 0..<frameCountInt {
                    if frame < totalSamples {
                        let monoValue = srcFloatData[frame]
                        let int16Value = Int16(max(-1.0, min(1.0, monoValue)) * 32767.0)
                        dstInt16Data[frame * 2] = int16Value      // å·¦å£°é“
                        dstInt16Data[frame * 2 + 1] = int16Value  // å³å£°é“
                    }
                }
                Logger.shared.debug("ğŸ”„ å•å£°é“è½¬ç«‹ä½“å£°å®Œæˆ")
            } else if inputChannels == outputChannels {
                // å£°é“æ•°åŒ¹é…ï¼šç›´æ¥è½¬æ¢
                for frame in 0..<frameCountInt {
                    for channel in 0..<outputChannels {
                        let srcIndex = frame * inputChannels + channel
                        if srcIndex < totalSamples {
                            let floatValue = srcFloatData[srcIndex]
                            let int16Value = Int16(max(-1.0, min(1.0, floatValue)) * 32767.0)
                            dstInt16Data[frame * outputChannels + channel] = int16Value
                        }
                    }
                }
                Logger.shared.debug("ğŸ”„ ç›´æ¥è½¬æ¢å®Œæˆ")
            } else {
                // å…¶ä»–æƒ…å†µï¼šå°è¯•äº¤é”™æ ¼å¼è§£æ
                let channelDataSize = min(totalSamples / inputChannels, frameCountInt)
                for frame in 0..<channelDataSize {
                    for channel in 0..<min(outputChannels, inputChannels) {
                        let srcIndex = frame * inputChannels + channel
                        if srcIndex < totalSamples {
                            let floatValue = srcFloatData[srcIndex]
                            let int16Value = Int16(max(-1.0, min(1.0, floatValue)) * 32767.0)
                            dstInt16Data[frame * outputChannels + channel] = int16Value
                        }
                    }
                }
                Logger.shared.debug("ğŸ”„ äº¤é”™æ ¼å¼è§£æå®Œæˆ")
            }
        }
        
        return outputData
    }
    
    /// å¤åˆ¶éŸ³é¢‘æ•°æ®åˆ°PCMç¼“å†²åŒºï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
    static func copyAudioDataToPCMBuffer(
        from bufferList: AudioBufferList,
        to pcmBuffer: AVAudioPCMBuffer,
        frameCount: UInt32,
        inputChannels: Int,
        outputChannels: Int
    ) -> Bool {
        guard bufferList.mNumberBuffers == 1 else {
            Logger.shared.warning("âš ï¸ ä¸æ”¯æŒå¤šç¼“å†²åŒºæ ¼å¼")
            return false
        }
        
        let buffer = bufferList.mBuffers
        guard let srcData = buffer.mData, buffer.mDataByteSize > 0 else {
            Logger.shared.warning("âš ï¸ è¾“å…¥æ•°æ®ä¸ºç©º")
            return false
        }
        
        let frameCountInt = Int(frameCount)
        let totalSamples = Int(buffer.mDataByteSize) / MemoryLayout<Float>.size
        
        Logger.shared.debug("ğŸ”„ PCMç¼“å†²åŒºæ•°æ®å¤åˆ¶: è¾“å…¥å£°é“=\(inputChannels), è¾“å‡ºå£°é“=\(outputChannels), å¸§æ•°=\(frameCountInt)")
        
        if let dstChannelData = pcmBuffer.floatChannelData {
            // è¾“å‡ºæ ¼å¼æ˜¯32ä½æµ®ç‚¹
            let srcFloatData = srcData.assumingMemoryBound(to: Float.self)
            
            if inputChannels == 1 && outputChannels == 2 {
                // å•å£°é“è½¬ç«‹ä½“å£°
                for frame in 0..<frameCountInt {
                    if frame < totalSamples {
                        let monoValue = srcFloatData[frame]
                        dstChannelData[0][frame] = monoValue  // å·¦å£°é“
                        dstChannelData[1][frame] = monoValue  // å³å£°é“
                    }
                }
                Logger.shared.debug("ğŸ”„ å•å£°é“è½¬ç«‹ä½“å£°å®Œæˆ")
            } else if inputChannels == outputChannels {
                // å£°é“æ•°åŒ¹é…ï¼šç›´æ¥å¤åˆ¶
                for frame in 0..<frameCountInt {
                    for channel in 0..<outputChannels {
                        let srcIndex = frame * inputChannels + channel
                        if srcIndex < totalSamples {
                            dstChannelData[channel][frame] = srcFloatData[srcIndex]
                        }
                    }
                }
                Logger.shared.debug("ğŸ”„ ç›´æ¥å¤åˆ¶å®Œæˆ")
            } else {
                // å…¶ä»–æƒ…å†µï¼šå°è¯•äº¤é”™æ ¼å¼è§£æ
                let channelDataSize = min(totalSamples / inputChannels, frameCountInt)
                for frame in 0..<channelDataSize {
                    for channel in 0..<min(outputChannels, inputChannels) {
                        let srcIndex = frame * inputChannels + channel
                        if srcIndex < totalSamples {
                            dstChannelData[channel][frame] = srcFloatData[srcIndex]
                        }
                    }
                }
                Logger.shared.debug("ğŸ”„ äº¤é”™æ ¼å¼è§£æå®Œæˆ")
            }
            
            pcmBuffer.frameLength = UInt32(frameCountInt)
            return true
            
        } else if let dstChannelData = pcmBuffer.int16ChannelData {
            // è¾“å‡ºæ ¼å¼æ˜¯16ä½æ•´æ•°
            let srcFloatData = srcData.assumingMemoryBound(to: Float.self)
            
            if inputChannels == 1 && outputChannels == 2 {
                // å•å£°é“è½¬ç«‹ä½“å£°
                for frame in 0..<frameCountInt {
                    if frame < totalSamples {
                        let monoValue = Int16(srcFloatData[frame] * 32767.0)
                        dstChannelData[0][frame] = monoValue  // å·¦å£°é“
                        dstChannelData[1][frame] = monoValue  // å³å£°é“
                    }
                }
                Logger.shared.debug("ğŸ”„ å•å£°é“è½¬ç«‹ä½“å£°å®Œæˆ")
            } else if inputChannels == outputChannels {
                // å£°é“æ•°åŒ¹é…ï¼šç›´æ¥è½¬æ¢
                for frame in 0..<frameCountInt {
                    for channel in 0..<outputChannels {
                        let srcIndex = frame * inputChannels + channel
                        if srcIndex < totalSamples {
                            dstChannelData[channel][frame] = Int16(srcFloatData[srcIndex] * 32767.0)
                        }
                    }
                }
                Logger.shared.debug("ğŸ”„ ç›´æ¥è½¬æ¢å®Œæˆ")
            } else {
                // å…¶ä»–æƒ…å†µï¼šå°è¯•äº¤é”™æ ¼å¼è§£æ
                let channelDataSize = min(totalSamples / inputChannels, frameCountInt)
                for frame in 0..<channelDataSize {
                    for channel in 0..<min(outputChannels, inputChannels) {
                        let srcIndex = frame * inputChannels + channel
                        if srcIndex < totalSamples {
                            dstChannelData[channel][frame] = Int16(srcFloatData[srcIndex] * 32767.0)
                        }
                    }
                }
                Logger.shared.debug("ğŸ”„ äº¤é”™æ ¼å¼è§£æå®Œæˆ")
            }
            
            pcmBuffer.frameLength = UInt32(frameCountInt)
            return true
        }
        
        Logger.shared.warning("âš ï¸ ä¸æ”¯æŒçš„PCMç¼“å†²åŒºæ ¼å¼")
        return false
    }
    
    /// è®¡ç®—éŸ³é¢‘ç”µå¹³ï¼ˆä»AudioBufferListï¼‰
    static func calculateAudioLevel(from bufferList: AudioBufferList, frameCount: UInt32) -> (maxLevel: Float, rmsLevel: Float, normalizedLevel: Float) {
        let buffer = bufferList.mBuffers
        guard let data = buffer.mData, buffer.mDataByteSize > 0 else {
            return (0.0, 0.0, 0.0)
        }
        
        let samples = data.assumingMemoryBound(to: Float.self)
        let sampleCount = Int(buffer.mDataByteSize) / MemoryLayout<Float>.size
        
        var maxLevel: Float = 0.0
        var sumSquares: Float = 0.0
        
        for i in 0..<sampleCount {
            let sample = abs(samples[i])
            if sample > maxLevel {
                maxLevel = sample
            }
            sumSquares += sample * sample
        }
        
        // è®¡ç®— RMS
        let rmsLevel = sampleCount > 0 ? sqrt(sumSquares / Float(sampleCount)) : 0.0
        
        // è½¬æ¢ä¸º dB
        let _ = maxLevel > 0 ? 20 * log10(maxLevel) : -96.0 // æš‚æ—¶æœªä½¿ç”¨ï¼Œä½†ä¿ç•™ä»¥å¤‡å°†æ¥ä½¿ç”¨
        let rmsDB = rmsLevel > 0 ? 20 * log10(rmsLevel) : -96.0
        let normalizedLevel = max(0, min(1, (rmsDB + 96) / 96))
        
        return (maxLevel, rmsLevel, normalizedLevel)
    }
}

/// éŸ³é¢‘æ•°æ®è½¬æ¢é”™è¯¯ç±»å‹
enum AudioDataConversionError: Error, LocalizedError {
    case unsupportedBufferCount(UInt32)
    case emptyInputData
    case unsupportedFormat
    case conversionFailed(String)
    
    var errorDescription: String? {
        switch self {
        case .unsupportedBufferCount(let count):
            return "ä¸æ”¯æŒçš„ç¼“å†²åŒºæ•°é‡: \(count)"
        case .emptyInputData:
            return "è¾“å…¥æ•°æ®ä¸ºç©º"
        case .unsupportedFormat:
            return "ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼"
        case .conversionFailed(let reason):
            return "æ•°æ®è½¬æ¢å¤±è´¥: \(reason)"
        }
    }
}

/// éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯ç»“æ„
struct AudioFileInfo {
    let url: URL
    let duration: Double
    let sampleRate: Double
    let channels: AVAudioChannelCount
    let format: AVAudioCommonFormat
    
    var formattedDuration: String {
        let minutes = Int(duration) / 60
        let seconds = Int(duration) % 60
        return String(format: "%02d:%02d", minutes, seconds)
    }
    
    var formattedSampleRate: String {
        return String(format: "%.0f Hz", sampleRate)
    }
    
    var formattedChannels: String {
        return channels == 1 ? "å•å£°é“" : "ç«‹ä½“å£°"
    }
}

// MARK: - Process Tap Constants
/// CoreAudio Process Tap ç›¸å…³å¸¸é‡å®šä¹‰
extension AudioUtils {
    
    /// Process Tap å±æ€§å¸¸é‡
    static let kAudioTapPropertyUID: AudioObjectPropertySelector = AudioObjectPropertySelector(0x74706175) // 'tpau' - Tap Property UID
    static let kAudioTapPropertyFormat: AudioObjectPropertySelector = AudioObjectPropertySelector(kAudioDevicePropertyStreamFormat) // ä½¿ç”¨æ ‡å‡†æµæ ¼å¼å±æ€§
    static let kAudioTapPropertyIsActive: AudioObjectPropertySelector = AudioObjectPropertySelector(0x74617061) // 'tapa' - Tap Property IsActive
    
    /// Process Tap ç›¸å…³é”™è¯¯ä»£ç 
    static let kAudioTapErrorNotAvailable: OSStatus = OSStatus(0x7470616E) // 'tpan' - Tap Not Available
    
    /// Aggregate Device ç›¸å…³å¸¸é‡
    static let kAudioAggregateDevicePropertyTapAutoStart: AudioObjectPropertySelector = AudioObjectPropertySelector(0x74617073) // 'taps' - Tap Auto Start
    static let kAudioTapErrorAlreadyExists: OSStatus = OSStatus(0x74706165) // 'tpae' - Tap Already Exists
}
