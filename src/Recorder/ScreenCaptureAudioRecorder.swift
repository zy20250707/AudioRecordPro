import Foundation
import AVFoundation
import CoreMedia
import ScreenCaptureKit

/// ç³»ç»ŸéŸ³é¢‘å½•åˆ¶å™¨ (åŸºäºŽ ScreenCaptureKit)
@MainActor
class ScreenCaptureAudioRecorder: BaseAudioRecorder {
    
    // MARK: - Properties
    private var screenCaptureStream: SCStream?
    private var retryCount = 0
    private let screenFrameOutputQueue = DispatchQueue(label: "SCStream.screen.queue", qos: .utility)
    private let audioFrameOutputQueue = DispatchQueue(label: "SCStream.audio.queue", qos: .userInitiated)
    private var audioOutputRef: SystemAudioStreamOutput?
    private var videoOutputRef: MinimalVideoStreamOutput?
    private var isStopping = false
    
    // MARK: - Initialization
    override init(mode: AudioUtils.RecordingMode) {
        super.init(mode: .systemMixdown)
    }
    
    // MARK: - Recording Implementation
    override func startRecording() {
        guard !isRunning else {
            logger.warning("å½•åˆ¶å·²åœ¨è¿›è¡Œä¸­")
            return
        }
        
        let url = fileManager.getRecordingFileURL(recordingMode: recordingMode, format: currentFormat.fileExtension)
        logger.info("å¼€å§‹å½•åˆ¶ï¼Œæ¨¡å¼: \(recordingMode.rawValue), æ ¼å¼: \(currentFormat.rawValue)")
        
        do {
            // Create audio file for system audio
            try createSystemAudioFile(at: url, format: currentFormat)
            
            // Start system audio capture
            startSystemAudioCapture()
            
            // Start monitoring
            levelMonitor.startMonitoring(source: .simulated)
            
            isRunning = true
            
        } catch {
            let errorMsg = "æ–‡ä»¶åˆ›å»ºå¤±è´¥: \(error.localizedDescription)"
            onStatus?(errorMsg)
            logger.error("åˆ›å»ºéŸ³é¢‘æ–‡ä»¶å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    override func stopRecording() {
        guard !isStopping else { return }
        isStopping = true
        
        if let stream = screenCaptureStream {
            Task { @MainActor in
                // åœæ­¢å‰ç§»é™¤è¾“å‡ºï¼Œé¿å…å›žè°ƒè¿‡ç¨‹ä¸­è®¿é—®å·²é‡Šæ”¾èµ„æº
                if let audioOut = self.audioOutputRef {
                    try? stream.removeStreamOutput(audioOut, type: .audio)
                }
                if let videoOut = self.videoOutputRef {
                    try? stream.removeStreamOutput(videoOut, type: .screen)
                }
                
                do {
                    try await stream.stopCapture()
                    self.logger.info("ç³»ç»ŸéŸ³é¢‘å½•åˆ¶å·²åœæ­¢")
                } catch {
                    self.logger.error("åœæ­¢ç³»ç»ŸéŸ³é¢‘å½•åˆ¶å¤±è´¥: \(error.localizedDescription)")
                }
                
                // æ¸…ç†å¼•ç”¨
                self.audioOutputRef = nil
                self.videoOutputRef = nil
                self.screenCaptureStream = nil
                
                // å†è°ƒç”¨çˆ¶ç±»åœæ­¢ï¼Œç»Ÿä¸€ç”Ÿæˆå½•éŸ³è®°å½•ä¸Žå›žè°ƒ
                super.stopRecording()
                self.isStopping = false
            }
        } else {
            isStopping = false
            super.stopRecording()
        }
    }
    
    // MARK: - Private Methods
    private func createSystemAudioFile(at url: URL, format: AudioUtils.AudioFormat) throws {
        // Use 48000Hz sample rate (consistent with ScreenCaptureKit)
        var settings = format.settings
        settings[AVSampleRateKey] = 48000  // Match ScreenCaptureKit configuration
        
        audioFile = try AVAudioFile(forWriting: url, settings: settings)
        outputURL = url
        
        onStatus?("æ–‡ä»¶åˆ›å»ºæˆåŠŸ: \(url.lastPathComponent)")
        logger.info("ç³»ç»ŸéŸ³é¢‘æ–‡ä»¶åˆ›å»ºæˆåŠŸ: \(url.lastPathComponent)")
        logger.info("æ–‡ä»¶æ ¼å¼: \(audioFile?.processingFormat.settings ?? [:])")
    }
    
    private func startSystemAudioCapture() {
        logger.info("å¼€å§‹ç³»ç»ŸéŸ³é¢‘å½•åˆ¶ï¼ˆä½¿ç”¨ScreenCaptureKitï¼‰")
        
        // Check system version
        guard #available(macOS 12.3, *) else {
            onStatus?("ç³»ç»Ÿç‰ˆæœ¬ä¸æ”¯æŒScreenCaptureKitï¼Œéœ€è¦macOS 12.3+")
            logger.error("ç³»ç»Ÿç‰ˆæœ¬ä¸æ”¯æŒScreenCaptureKit")
            return
        }
        
        logger.info("ç³»ç»Ÿç‰ˆæœ¬æ”¯æŒScreenCaptureKit")
        
        // Check screen recording permission
        checkScreenRecordingPermission { [weak self] hasPermission in
            guard let self = self else { return }
            
            if !hasPermission {
                Task { @MainActor in
                    self.onStatus?("éœ€è¦å±å¹•å½•åˆ¶æƒé™æ‰èƒ½å½•åˆ¶ç³»ç»Ÿå£°éŸ³ï¼Œè¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­å…è®¸")
                }
                self.logger.error("å±å¹•å½•åˆ¶æƒé™ä¸è¶³")
                return
            }
            
            // Get shareable content
            Task { [weak self] in
                guard let self = self else { return }
                
                self.logger.info("å¼€å§‹èŽ·å–å¯å…±äº«å†…å®¹...")
                do {
                    // Add timeout handling
                    let content = try await withThrowingTaskGroup(of: SCShareableContent.self) { group in
                        group.addTask {
                            try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: true)
                        }
                        
                        group.addTask {
                            try await Task.sleep(nanoseconds: 10_000_000_000) // 10 second timeout
                            throw NSError(domain: "Timeout", code: -1, userInfo: [NSLocalizedDescriptionKey: "èŽ·å–å¯å…±äº«å†…å®¹è¶…æ—¶"])
                        }
                        
                        let result = try await group.next()!
                        group.cancelAll()
                        return result
                    }
                    
                    self.logger.info("âœ… èŽ·å–åˆ°å¯å…±äº«å†…å®¹ï¼Œæ˜¾ç¤ºå™¨æ•°é‡: \(content.displays.count)")
                    
                    // Check for available displays
                    guard let display = content.displays.first else {
                        self.logger.error("æ²¡æœ‰å¯ç”¨çš„æ˜¾ç¤ºå™¨")
                        Task { @MainActor in
                            self.onStatus?("æ²¡æœ‰å¯ç”¨çš„æ˜¾ç¤ºå™¨ï¼Œæ— æ³•å½•åˆ¶ç³»ç»ŸéŸ³é¢‘")
                        }
                        return
                    }
                    
                    self.logger.info("ä½¿ç”¨æ˜¾ç¤ºå™¨: \(display.displayID)")
                    
                    // åˆ›å»ºè¿‡æ»¤å™¨ï¼šæŒ‰ WWDC å»ºè®®æŽ’é™¤å½“å‰åº”ç”¨ï¼Œé¿å…é•œåƒ/åé¦ˆ
                    let excludedApps = content.applications.filter { app in
                        Bundle.main.bundleIdentifier == app.bundleIdentifier
                    }
                    let filter = SCContentFilter(
                        display: display,
                        excludingApplications: excludedApps,
                        exceptingWindows: []
                    )
                    
                    // Configure stream - enable audio and video capture
                    let config = SCStreamConfiguration()
                    
                    // Audio configuration
                    config.capturesAudio = true
                    // æš‚æ—¶ä¸æŽ’é™¤æœ¬è¿›ç¨‹éŸ³é¢‘ï¼Œé¿å…æµ‹è¯•é˜¶æ®µè¯¯æŽ’é™¤
                    config.excludesCurrentProcessAudio = false
                    config.sampleRate = 48000  // Use unified 48000Hz sample rate
                    config.channelCount = 2    // Stereo
                    
                    // Video configuration (needed to drive audio capture)
                    config.width = 320
                    config.height = 240
                    config.minimumFrameInterval = CMTime(value: 1, timescale: 60) // 60fpsï¼Œä¸Žç¤ºä¾‹ä¸€è‡´ï¼Œä¿è¯éŸ³é¢‘é©±åŠ¨ç¨³å®š
                    config.showsCursor = false
                    // æé«˜é˜Ÿåˆ—æ·±åº¦ï¼Œé¿å…é«˜å¸§çŽ‡ä¸‹ä¸¢å¸§ï¼ˆä¸Žç¤ºä¾‹ä¸€è‡´ï¼‰
                    config.queueDepth = 5
                    
                    self.logger.info("SCStreamConfigurationè®¾ç½®å®Œæˆ - éŸ³é¢‘: \(config.capturesAudio), å°ºå¯¸: \(config.width)x\(config.height), é‡‡æ ·çŽ‡: \(config.sampleRate)")
                    
                    // Create stream
                    do {
                        self.logger.info("æ­£åœ¨åˆ›å»ºSCStream...")
                        let stream = SCStream(filter: filter, configuration: config, delegate: self)
                        self.logger.info("SCStreamåˆ›å»ºæˆåŠŸ")
                        
                        // Check delegate setup
                        self.logger.info("SCStream delegateå·²è®¾ç½®")
                        
                        // Add audio output
                        self.logger.info("æ­£åœ¨æ·»åŠ éŸ³é¢‘è¾“å‡º...")
                        let audioOutput = SystemAudioStreamOutput(audioFile: self.audioFile, onLevel: self.onLevel)
                        do {
                            try stream.addStreamOutput(audioOutput, type: .audio, sampleHandlerQueue: audioFrameOutputQueue)
                            self.audioOutputRef = audioOutput
                            self.logger.info("âœ… éŸ³é¢‘è¾“å‡ºæ·»åŠ æˆåŠŸ")
                        } catch {
                            self.logger.error("âŒ éŸ³é¢‘è¾“å‡ºæ·»åŠ å¤±è´¥: \(error.localizedDescription)")
                            throw error
                        }
                        
                        // Add video output (minimal processing, only to drive audio stream)
                        self.logger.info("æ­£åœ¨æ·»åŠ è§†é¢‘è¾“å‡º...")
                        let videoOutput = MinimalVideoStreamOutput()
                        do {
                            try stream.addStreamOutput(videoOutput, type: .screen, sampleHandlerQueue: screenFrameOutputQueue)
                            self.videoOutputRef = videoOutput
                            self.logger.info("âœ… è§†é¢‘è¾“å‡ºæ·»åŠ æˆåŠŸ")
                        } catch {
                            self.logger.error("âŒ è§†é¢‘è¾“å‡ºæ·»åŠ å¤±è´¥: \(error.localizedDescription)")
                            throw error
                        }
                        
                        // Add debug: check stream output types
                        self.logger.info("Streamè¾“å‡ºç±»åž‹æ£€æŸ¥: å·²æ·»åŠ éŸ³é¢‘å’Œè§†é¢‘è¾“å‡ºå¤„ç†å™¨")
                        
                        // Add debug: check stream status
                        self.logger.info("Streamé…ç½® - éŸ³é¢‘æ•èŽ·: \(config.capturesAudio), é‡‡æ ·çŽ‡: \(config.sampleRate)")
                        
                        self.screenCaptureStream = stream
                        self.logger.info("screenCaptureStreamå·²è®¾ç½®")
                        
                        // Start capture
                        self.logger.info("å‡†å¤‡å¼€å§‹æ•èŽ·ï¼Œstreamå¯¹è±¡: \(stream)")
                        do {
                            try await stream.startCapture()
                            self.logger.info("ç³»ç»ŸéŸ³é¢‘å½•åˆ¶å¯åŠ¨æˆåŠŸ")
                            
                            // Post-startup status check
                            self.logger.info("å¯åŠ¨åŽStreamçŠ¶æ€æ£€æŸ¥å®Œæˆ")
                            
                            // Add delayed check to see if there's data flow
                            DispatchQueue.main.asyncAfter(deadline: .now() + 2.0) {
                                self.logger.info("2ç§’åŽæ£€æŸ¥ï¼šStreamå¯¹è±¡: \(stream)")
                                self.logger.info("2ç§’åŽæ£€æŸ¥ï¼šStreamé…ç½®: \(config)")
                                
                                // Try playing test audio to verify audio capture
                                self.logger.info("å°è¯•æ’­æ”¾æµ‹è¯•éŸ³é¢‘æ¥éªŒè¯éŸ³é¢‘æ•èŽ·...")
                                NSSound.beep()
                            }
                            
                            Task { @MainActor in
                                self.onStatus?("ç³»ç»ŸéŸ³é¢‘å½•åˆ¶å·²å¼€å§‹")
                            }
                        } catch {
                            self.logger.error("ç³»ç»ŸéŸ³é¢‘å½•åˆ¶å¯åŠ¨å¤±è´¥: \(error.localizedDescription)")
                            self.logger.error("é”™è¯¯è¯¦æƒ…: \(error)")
                            
                            Task { @MainActor in
                                self.onStatus?("ç³»ç»ŸéŸ³é¢‘å½•åˆ¶å¯åŠ¨å¤±è´¥: \(error.localizedDescription)")
                                
                                // Check if it's a permission issue
                                if error.localizedDescription.contains("permission") || 
                                   error.localizedDescription.contains("æƒé™") ||
                                   error.localizedDescription.contains("denied") {
                                    self.onStatus?("éœ€è¦å±å¹•å½•åˆ¶æƒé™æ‰èƒ½å½•åˆ¶ç³»ç»Ÿå£°éŸ³ï¼Œè¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­å…è®¸")
                                }
                            }
                        }
                        
                    } catch {
                        self.onStatus?("åˆ›å»ºç³»ç»ŸéŸ³é¢‘æµå¤±è´¥: \(error.localizedDescription)")
                        self.logger.error("åˆ›å»ºç³»ç»ŸéŸ³é¢‘æµå¤±è´¥: \(error.localizedDescription)")
                    }
                    
                } catch {
                    self.onStatus?("èŽ·å–ç³»ç»ŸéŸ³é¢‘å¤±è´¥: \(error.localizedDescription)")
                    self.logger.error("èŽ·å–å¯å…±äº«å†…å®¹å¤±è´¥: \(error.localizedDescription)")
                }
            }
        }
    }
    
    /// Check screen recording permission
    private func checkScreenRecordingPermission(completion: @escaping (Bool) -> Void) {
        // Try to get shareable content to check permission
        Task {
            do {
                let _ = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: true)
                // Able to get content means permission is normal
                completion(true)
            } catch {
                // Check if it's a permission error
                if error.localizedDescription.contains("permission") || 
                   error.localizedDescription.contains("æƒé™") ||
                   error.localizedDescription.contains("denied") {
                    completion(false)
                } else {
                    // Other errors, permission might be fine
                    completion(true)
                }
            }
        }
    }
}

// MARK: - SCStreamDelegate
extension ScreenCaptureAudioRecorder: SCStreamDelegate {
    nonisolated func stream(_ stream: SCStream, didStopWithError error: Error) {
        Task { @MainActor in
            self.logger.error("SCStreamåœæ­¢ï¼Œé”™è¯¯: \(error.localizedDescription)")
            self.isRunning = false
            self.onStatus?("ç³»ç»ŸéŸ³é¢‘å½•åˆ¶æ„å¤–åœæ­¢: \(error.localizedDescription)")
        }
    }
}

// MARK: - MinimalVideoStreamOutput
class MinimalVideoStreamOutput: NSObject, SCStreamOutput {
    private let logger = Logger.shared
    
    func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of type: SCStreamOutputType) {
        // Minimal processing, only to drive audio stream
        if type == .screen {
            // Don't process video data, just log receipt
            logger.info("ðŸ“º æ”¶åˆ°è§†é¢‘æ•°æ®ï¼Œå¸§æ•°: \(CMSampleBufferGetNumSamples(sampleBuffer))")
        }
    }
}

// MARK: - SystemAudioStreamOutput
class SystemAudioStreamOutput: NSObject, SCStreamOutput {
    private weak var audioFile: AVAudioFile?
    private let onLevel: ((Float) -> Void)?
    private let logger = Logger.shared
    private var audioDataReceived = false
    private var audioDataTimer: Timer?
    
    init(audioFile: AVAudioFile?, onLevel: ((Float) -> Void)?) {
        self.audioFile = audioFile
        self.onLevel = onLevel
        super.init()
        
        // Start timer on main thread to detect audio data reception
        DispatchQueue.main.async {
            self.audioDataTimer = Timer.scheduledTimer(withTimeInterval: 5.0, repeats: true) { [weak self] _ in
                guard let self = self else { return }
                if !self.audioDataReceived {
                    self.logger.warning("âš ï¸ 5ç§’å†…æœªæŽ¥æ”¶åˆ°ä»»ä½•éŸ³é¢‘æ•°æ®ï¼Œå¯èƒ½ç³»ç»Ÿæ²¡æœ‰æ’­æ”¾éŸ³é¢‘æˆ–æƒé™é—®é¢˜")
                }
            }
        }
    }
    
    deinit {
        audioDataTimer?.invalidate()
    }
    
    func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of type: SCStreamOutputType) {
        logger.info("ðŸŽµ SystemAudioStreamOutputæ”¶åˆ°æ•°æ®ï¼Œç±»åž‹: \(type)")
        
        guard sampleBuffer.isValid else { return }
        guard type == .audio else { 
            logger.info("å¿½ç•¥éžéŸ³é¢‘æ•°æ®ï¼Œç±»åž‹: \(type)")
            return 
        }
        
        // Mark that audio data has been received
        audioDataReceived = true
        
        // Add detailed audio data debug info
        let frameCount = CMSampleBufferGetNumSamples(sampleBuffer)
        let duration = CMTimeGetSeconds(CMSampleBufferGetDuration(sampleBuffer))
        logger.info("ðŸŽµ éŸ³é¢‘æ ·æœ¬ç¼“å†²åŒº - å¸§æ•°: \(frameCount), æ—¶é•¿: \(duration)ç§’")
        
        logger.info("ðŸŽµ å¤„ç†éŸ³é¢‘æ ·æœ¬ç¼“å†²åŒºï¼Œå¸§æ•°: \(CMSampleBufferGetNumSamples(sampleBuffer))")
        
        // Process audio sample buffer
        guard let audioFile = audioFile else { 
            logger.error("audioFileä¸ºnil")
            return 
        }
        
        // Convert CMSampleBuffer to AVAudioPCMBuffer
        if let audioBuffer = convertToAudioBuffer(from: sampleBuffer) {
            do {
                try audioFile.write(from: audioBuffer)
                
                // Calculate level
                let level = calculateRMSLevel(from: audioBuffer)
                
                // Add debug info
                if level > 0.01 { // Only print when there's significant level
                    logger.info("ç³»ç»ŸéŸ³é¢‘å½•åˆ¶ç”µå¹³: \(String(format: "%.3f", level)), å¸§æ•°: \(audioBuffer.frameLength)")
                }
                
                // Update level display in real-time
                DispatchQueue.main.async {
                    self.onLevel?(level)
                }
                
            } catch {
                logger.error("å†™å…¥ç³»ç»ŸéŸ³é¢‘å¤±è´¥: \(error.localizedDescription)")
            }
        } else {
            // Even if conversion fails, try to calculate level from raw audio data
            let level = calculateLevelFromSampleBuffer(sampleBuffer)
            Task { @MainActor in
                self.onLevel?(level)
            }
        }
    }
    
    private func convertToAudioBuffer(from sampleBuffer: CMSampleBuffer) -> AVAudioPCMBuffer? {
        guard let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer) else {
            logger.error("æ— æ³•èŽ·å–æ ¼å¼æè¿°")
            return nil
        }
        
        guard let asbd = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription) else {
            logger.error("æ— æ³•èŽ·å–éŸ³é¢‘æµåŸºæœ¬æè¿°")
            return nil
        }
        
        guard let format = AVAudioFormat(streamDescription: asbd) else {
            logger.error("æ— æ³•åˆ›å»ºAVAudioFormat")
            return nil
        }
        
        let frameCount = CMSampleBufferGetNumSamples(sampleBuffer)
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(frameCount)) else {
            logger.error("æ— æ³•åˆ›å»ºPCMç¼“å†²åŒº")
            return nil
        }
        buffer.frameLength = AVAudioFrameCount(frameCount)
        
        // ä½¿ç”¨ç³»ç»Ÿ API ç›´æŽ¥å°† PCM æ•°æ®æ‹·è´åˆ° AudioBufferListï¼Œé¿å…æ‰‹åŠ¨æŒ‡é’ˆå¤„ç†å¯¼è‡´é™éŸ³
        let status = CMSampleBufferCopyPCMDataIntoAudioBufferList(sampleBuffer,
                                                                 at: 0,
                                                                 frameCount: Int32(frameCount),
                                                                 into: buffer.mutableAudioBufferList)
        if status != noErr {
            logger.error("CMSampleBuffer æ‹·è´åˆ° AudioBufferList å¤±è´¥: \(status)")
            return nil
        }
        return buffer
    }
    
    private func calculateRMSLevel(from buffer: AVAudioPCMBuffer) -> Float {
        guard let channelData = buffer.floatChannelData?[0] else { return 0.0 }
        let frameCount = Int(buffer.frameLength)
        
        guard frameCount > 0 else { return 0.0 }
        
        var sum: Float = 0.0
        for i in 0..<frameCount {
            let sample = channelData[i]
            sum += sample * sample
        }
        
        let rms = sqrt(sum / Float(frameCount))
        return min(1.0, rms * 20.0)
    }
    
    private func calculateLevelFromSampleBuffer(_ sampleBuffer: CMSampleBuffer) -> Float {
        guard let blockBuffer = CMSampleBufferGetDataBuffer(sampleBuffer) else { return 0.0 }
        
        var length: Int = 0
        var dataPointer: UnsafeMutablePointer<Int8>?
        let status = CMBlockBufferGetDataPointer(blockBuffer, atOffset: 0, lengthAtOffsetOut: nil, totalLengthOut: &length, dataPointerOut: &dataPointer)
        
        guard status == noErr, let data = dataPointer, length > 0 else { return 0.0 }
        
        // Simplified calculation assuming 16-bit samples
        let sampleCount = length / MemoryLayout<Int16>.size
        let rawPtr = UnsafeMutableRawPointer(data)
        let samples = rawPtr.bindMemory(to: Int16.self, capacity: sampleCount)
        
        var sum: Float = 0.0
        for i in 0..<sampleCount {
            let sample = Float(samples[i]) / Float(Int16.max)
            sum += sample * sample
        }
        
        let rms = sqrt(sum / Float(sampleCount))
        return min(1.0, rms * 20.0)
    }
}