import Foundation
import AVFoundation
import CoreAudio
import AudioToolbox

// MARK: - å…¨å±€ C å‡½æ•°æŒ‡é’ˆ
/// å…¨å±€éŸ³é¢‘å›è°ƒå‡½æ•°ï¼ˆC å‡½æ•°æŒ‡é’ˆï¼‰
@available(macOS 14.4, *)
func globalAudioCallback(
    inDevice: AudioDeviceID,
    inNow: UnsafePointer<AudioTimeStamp>,
    inInputData: UnsafePointer<AudioBufferList>,
    inInputTime: UnsafePointer<AudioTimeStamp>,
    inOutputData: UnsafeMutablePointer<AudioBufferList>,
    inOutputTime: UnsafePointer<AudioTimeStamp>,
    inClientData: UnsafeMutableRawPointer?
) -> OSStatus {
    // é€šè¿‡ inClientData è·å– AudioCallbackHandler å®ä¾‹
    guard let clientData = inClientData else {
        return noErr
    }
    
    let handler = Unmanaged<AudioCallbackHandler>.fromOpaque(clientData).takeUnretainedValue()
    
    // å¤„ç†éŸ³é¢‘æ•°æ®
    let bufferList = inInputData.pointee
    let buffer = bufferList.mBuffers
    
    // æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼ˆå‡å°‘é¢‘ç‡é¿å…æ—¥å¿—è¿‡å¤šï¼‰
    // ä½¿ç”¨å…¨å±€å˜é‡æ¥è·Ÿè¸ªè°ƒç”¨æ¬¡æ•°
    struct CallCounter {
        static var count = 0
        static var lastNonZeroDataSize = UInt32(0)
        static var nonZeroCount = 0
    }
    CallCounter.count += 1
    
    // è®°å½•éé›¶æ•°æ®å¤§å°çš„æƒ…å†µ
    if buffer.mDataByteSize > 0 {
        CallCounter.lastNonZeroDataSize = buffer.mDataByteSize
        CallCounter.nonZeroCount += 1
    }
    
    if CallCounter.count % 100 == 1 { // æ¯100æ¬¡å›è°ƒè®°å½•ä¸€æ¬¡
        handler.logger.debug("ğŸ§ éŸ³é¢‘å›è°ƒ[\(CallCounter.count)]: device=\(inDevice), dataSize=\(buffer.mDataByteSize), channels=\(bufferList.mNumberBuffers)")
        handler.logger.debug("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: éé›¶æ•°æ®æ¬¡æ•°=\(CallCounter.nonZeroCount), æœ€åéé›¶å¤§å°=\(CallCounter.lastNonZeroDataSize)")
    }
    
    // å¦‚æœè¿ç»­1000æ¬¡éƒ½æ˜¯0æ•°æ®ï¼Œå‘å‡ºè­¦å‘Š
    if CallCounter.count % 1000 == 0 && CallCounter.nonZeroCount == 0 {
        handler.logger.warning("âš ï¸ è­¦å‘Š: å·²è°ƒç”¨\(CallCounter.count)æ¬¡éŸ³é¢‘å›è°ƒï¼Œä½†ä»æœªæ”¶åˆ°æœ‰æ•ˆæ•°æ®ï¼")
        handler.logger.warning("ğŸ’¡ å»ºè®®: æ£€æŸ¥Process Tapé…ç½®æˆ–QQéŸ³ä¹æ˜¯å¦çœŸçš„åœ¨æ’­æ”¾éŸ³é¢‘")
    }
    
    // è®¡ç®—å®é™…çš„å¸§æ•°ï¼šå­—èŠ‚æ•°é™¤ä»¥æ¯å¸§å­—èŠ‚æ•°
    let bytesPerFrame = Int(buffer.mDataByteSize) / Int(bufferList.mNumberBuffers) / 4 // å‡è®¾32ä½æµ®ç‚¹
    let frameCount = UInt32(bytesPerFrame)
    
    // è®¡ç®—ç”µå¹³
    handler.calculateAndReportLevel(from: bufferList, frameCount: frameCount)
    
    // å†™å…¥éŸ³é¢‘æ•°æ®
    handler.writeAudioData(from: bufferList, frameCount: frameCount)
    
    return noErr
}

// MARK: - AudioCallbackHandler
/// éŸ³é¢‘å›è°ƒå¤„ç†å™¨ - è´Ÿè´£å¤„ç†éŸ³é¢‘æ•°æ®æµå’Œæ–‡ä»¶å†™å…¥
@available(macOS 14.4, *)
class AudioCallbackHandler {
    
    // MARK: - Properties
    let logger = Logger.shared
    private var audioFile: AVAudioFile?
    private var onLevel: ((Float) -> Void)?
    
    // MARK: - Initialization
    
    init() {}
    
    // MARK: - Public Methods
    
    /// è®¾ç½®éŸ³é¢‘æ–‡ä»¶
    func setAudioFile(_ file: AVAudioFile) {
        self.audioFile = file
    }
    
    /// è®¾ç½®ç”µå¹³å›è°ƒ
    func setLevelCallback(_ callback: @escaping (Float) -> Void) {
        self.onLevel = callback
    }
    
    /// åˆ›å»ºéŸ³é¢‘å›è°ƒå‡½æ•°
    func createAudioCallback() -> (AudioDeviceIOProc, UnsafeMutableRawPointer) {
        logger.info("ğŸ§ AudioCallbackHandler: åˆ›å»ºéŸ³é¢‘å›è°ƒå‡½æ•°...")
        // åˆ›å»º self çš„ä¸å®‰å…¨æŒ‡é’ˆï¼Œç”¨äºä¼ é€’ç»™ C å›è°ƒå‡½æ•°
        let selfPointer = Unmanaged.passUnretained(self).toOpaque()
        logger.info("âœ… éŸ³é¢‘å›è°ƒå‡½æ•°åˆ›å»ºæˆåŠŸï¼Œå®¢æˆ·ç«¯æ•°æ®æŒ‡é’ˆ: \(selfPointer)")
        return (globalAudioCallback, selfPointer)
    }
    
    /// åˆ›å»º PCM ç¼“å†²åŒº
    func makePCMBuffer(from bufferList: UnsafePointer<AudioBufferList>, frames: UInt32, asbd: AudioStreamBasicDescription) -> AVAudioPCMBuffer? {
        guard let audioFile = audioFile else { return nil }
        
        let format = audioFile.processingFormat
        guard let pcm = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(frames)) else {
            return nil
        }
        
        pcm.frameLength = AVAudioFrameCount(frames)
        
        let abl = bufferList.pointee
        let channels = Int(asbd.mChannelsPerFrame)
        let bytesPerFrame = Int(asbd.mBytesPerFrame)
        
        guard let src = abl.mBuffers.mData else { return nil }
        
        if let dst = pcm.floatChannelData {
            let frameStride = Int(bytesPerFrame)
            let totalFrames = Int(frames)
            for c in 0..<channels {
                var s = src.assumingMemoryBound(to: Float.self).advanced(by: c)
                var d = dst[c]
                for i in 0..<totalFrames {
                    d[i] = s.pointee
                    s = s.advanced(by: channels)
                }
            }
        } else if let dst = pcm.int16ChannelData {
            // å°†32ä½æµ®ç‚¹æ•°æ®è½¬æ¢ä¸º16ä½æ•´æ•°æ•°æ®
            let frameStride = Int(bytesPerFrame)
            let totalFrames = Int(frames)
            for c in 0..<channels {
                var s = src.assumingMemoryBound(to: Float.self).advanced(by: c)
                var d = dst[c]
                for i in 0..<totalFrames {
                    // å°†æµ®ç‚¹æ•°è½¬æ¢ä¸º16ä½æ•´æ•°ï¼š-1.0 åˆ° 1.0 æ˜ å°„åˆ° -32768 åˆ° 32767
                    let floatValue = s.pointee
                    let int16Value = Int16(max(-1.0, min(1.0, floatValue)) * 32767.0)
                    d[i] = int16Value
                    s = s.advanced(by: channels)
                }
            }
        } else if let dst = pcm.int32ChannelData {
            let frameStride = Int(bytesPerFrame)
            let totalFrames = Int(frames)
            for c in 0..<channels {
                var s = src.assumingMemoryBound(to: Int32.self).advanced(by: c)
                var d = dst[c]
                for i in 0..<totalFrames {
                    d[i] = s.pointee
                    s = s.advanced(by: channels)
                }
            }
        }
        
        return pcm
    }
    
    // MARK: - Private Methods
    
    func calculateAndReportLevel(from bufferList: AudioBufferList, frameCount: UInt32) {
        guard let onLevel = onLevel else { 
            logger.debug("AudioCallbackHandler: æ²¡æœ‰ç”µå¹³å›è°ƒå‡½æ•°")
            return 
        }
        
        let buffer = bufferList.mBuffers
        guard let data = buffer.mData else { 
            logger.debug("AudioCallbackHandler: éŸ³é¢‘æ•°æ®ä¸ºç©º")
            return 
        }
        
        let samples = data.assumingMemoryBound(to: Float.self)
        let sampleCount = Int(buffer.mDataByteSize) / MemoryLayout<Float>.size
        
        logger.debug("AudioCallbackHandler: è®¡ç®—ç”µå¹³ - frameCount: \(frameCount), sampleCount: \(sampleCount), dataSize: \(buffer.mDataByteSize)")
        
        var maxLevel: Float = 0.0
        var rmsLevel: Float = 0.0
        var sumSquares: Float = 0.0
        
        for i in 0..<sampleCount {
            let sample = abs(samples[i])
            if sample > maxLevel {
                maxLevel = sample
            }
            sumSquares += sample * sample
        }
        
        // è®¡ç®— RMS
        if sampleCount > 0 {
            rmsLevel = sqrt(sumSquares / Float(sampleCount))
        }
        
        // è½¬æ¢ä¸º dB
        let maxDB = maxLevel > 0 ? 20 * log10(maxLevel) : -96.0
        let rmsDB = rmsLevel > 0 ? 20 * log10(rmsLevel) : -96.0
        let normalizedLevel = max(0, min(1, (rmsDB + 96) / 96))
        
        logger.debug("AudioCallbackHandler: ç”µå¹³è®¡ç®— - maxLevel: \(maxLevel), rmsLevel: \(rmsLevel), maxDB: \(maxDB), rmsDB: \(rmsDB), normalized: \(normalizedLevel)")
        
        DispatchQueue.main.async {
            onLevel(normalizedLevel)
        }
    }
    
     func writeAudioData(from bufferList: AudioBufferList, frameCount: UInt32) {
        guard let audioFile = audioFile, frameCount > 0 else { 
            logger.debug("AudioCallbackHandler: è·³è¿‡å†™å…¥ - audioFile: \(audioFile != nil), frameCount: \(frameCount)")
            return 
        }
        
        logger.debug("AudioCallbackHandler: å‡†å¤‡å†™å…¥ \(frameCount) å¸§éŸ³é¢‘æ•°æ®")
        
        // åˆ›å»ºPCMç¼“å†²åŒºï¼Œç¡®ä¿å¤§å°è¶³å¤Ÿ
        guard let pcmBuffer = AVAudioPCMBuffer(pcmFormat: audioFile.processingFormat, frameCapacity: frameCount) else {
            logger.error("AudioCallbackHandler: æ— æ³•åˆ›å»ºPCMç¼“å†²åŒº")
            return
        }
        
        // å¤åˆ¶éŸ³é¢‘æ•°æ®åˆ°PCMç¼“å†²åŒº
        pcmBuffer.frameLength = frameCount
        
        // å¤åˆ¶bufferListä¸­çš„æ•°æ®åˆ°PCMç¼“å†²åŒº
        // å¯¹äºäº¤é”™æ ¼å¼ï¼Œæ‰€æœ‰å£°é“æ•°æ®åœ¨ä¸€ä¸ªbufferä¸­
        if bufferList.mNumberBuffers == 1 {
            let buffer = bufferList.mBuffers
            guard buffer.mData != nil && buffer.mDataByteSize > 0 else { return }
            
            if let dstChannelData = pcmBuffer.floatChannelData {
                let srcData = buffer.mData!.assumingMemoryBound(to: Float.self)
                let channels = Int(audioFile.processingFormat.channelCount)
                let frameCountInt = Int(frameCount)
                let channelDataSize = min(Int(buffer.mDataByteSize) / MemoryLayout<Float>.size / channels, frameCountInt)
                
                // äº¤é”™æ•°æ®ï¼šå·¦å£°é“ã€å³å£°é“ã€å·¦å£°é“ã€å³å£°é“...
                for frame in 0..<channelDataSize {
                    for channel in 0..<channels {
                        let srcIndex = frame * channels + channel
                        if srcIndex < Int(buffer.mDataByteSize) / MemoryLayout<Float>.size {
                            dstChannelData[channel][frame] = srcData[srcIndex]
                        }
                    }
                }
            } else if let dstChannelData = pcmBuffer.int16ChannelData {
                let srcData = buffer.mData!.assumingMemoryBound(to: Float.self)
                let channels = Int(audioFile.processingFormat.channelCount)
                let frameCountInt = Int(frameCount)
                let channelDataSize = min(Int(buffer.mDataByteSize) / MemoryLayout<Float>.size / channels, frameCountInt)
                
                // äº¤é”™æ•°æ®ï¼šå·¦å£°é“ã€å³å£°é“ã€å·¦å£°é“ã€å³å£°é“...
                for frame in 0..<channelDataSize {
                    for channel in 0..<channels {
                        let srcIndex = frame * channels + channel
                        if srcIndex < Int(buffer.mDataByteSize) / MemoryLayout<Float>.size {
                            // å°†æµ®ç‚¹æ•°è½¬æ¢ä¸º16ä½æ•´æ•°
                            let floatValue = srcData[srcIndex]
                            let int16Value = Int16(max(-1.0, min(1.0, floatValue)) * 32767.0)
                            dstChannelData[channel][frame] = int16Value
                        }
                    }
                }
            }
        }
        
        do {
            try audioFile.write(from: pcmBuffer)
            logger.debug("AudioCallbackHandler: æˆåŠŸå†™å…¥ \(frameCount) å¸§éŸ³é¢‘æ•°æ®")
        } catch {
            logger.error("AudioCallbackHandler: å†™å…¥éŸ³é¢‘æ–‡ä»¶å¤±è´¥: \(error.localizedDescription)")
        }
    }
}