import Foundation
import AVFoundation
import CoreAudio
import AudioToolbox

// MARK: - å…¨å±€ C å‡½æ•°æŒ‡é’ˆ
/// å…¨å±€éŸ³é¢‘å›è°ƒå‡½æ•°ï¼ˆC å‡½æ•°æŒ‡é’ˆï¼‰
@available(macOS 14.4, *)
func globalAudioCallback(
    inDevice: AudioDeviceID,
    inNow: UnsafePointer<AudioTimeStamp>,
    inInputData: UnsafePointer<AudioBufferList>,
    inInputTime: UnsafePointer<AudioTimeStamp>,
    inOutputData: UnsafeMutablePointer<AudioBufferList>,
    inOutputTime: UnsafePointer<AudioTimeStamp>,
    inClientData: UnsafeMutableRawPointer?
) -> OSStatus {
    // é€šè¿‡ inClientData è·å– AudioCallbackHandler å®ä¾‹
    guard let clientData = inClientData else {
        return noErr
    }
    
    let handler = Unmanaged<AudioCallbackHandler>.fromOpaque(clientData).takeUnretainedValue()
    
    // å¤„ç†éŸ³é¢‘æ•°æ®
    let bufferList = inInputData.pointee
    let buffer = bufferList.mBuffers
    
    // æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼ˆå‡å°‘é¢‘ç‡é¿å…æ—¥å¿—è¿‡å¤šï¼‰
    // ä½¿ç”¨å…¨å±€å˜é‡æ¥è·Ÿè¸ªè°ƒç”¨æ¬¡æ•°
    struct CallCounter {
        static var count = 0
        static var lastNonZeroDataSize = UInt32(0)
        static var nonZeroCount = 0
    }
    CallCounter.count += 1
    
    // è®°å½•éé›¶æ•°æ®å¤§å°çš„æƒ…å†µ
    if buffer.mDataByteSize > 0 {
        CallCounter.lastNonZeroDataSize = buffer.mDataByteSize
        CallCounter.nonZeroCount += 1
    }
    
    if CallCounter.count % 100 == 1 { // æ¯100æ¬¡å›è°ƒè®°å½•ä¸€æ¬¡
        handler.logger.debug("ğŸ§ éŸ³é¢‘å›è°ƒ[\(CallCounter.count)]: device=\(inDevice), dataSize=\(buffer.mDataByteSize), channels=\(bufferList.mNumberBuffers)")
        handler.logger.debug("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: éé›¶æ•°æ®æ¬¡æ•°=\(CallCounter.nonZeroCount), æœ€åéé›¶å¤§å°=\(CallCounter.lastNonZeroDataSize)")
    }
    
    // å¦‚æœè¿ç»­1000æ¬¡éƒ½æ˜¯0æ•°æ®ï¼Œå‘å‡ºè­¦å‘Š
    if CallCounter.count % 1000 == 0 && CallCounter.nonZeroCount == 0 {
        handler.logger.warning("âš ï¸ è­¦å‘Š: å·²è°ƒç”¨\(CallCounter.count)æ¬¡éŸ³é¢‘å›è°ƒï¼Œä½†ä»æœªæ”¶åˆ°æœ‰æ•ˆæ•°æ®ï¼")
        handler.logger.warning("ğŸ’¡ å»ºè®®: æ£€æŸ¥Process Tapé…ç½®æˆ–QQéŸ³ä¹æ˜¯å¦çœŸçš„åœ¨æ’­æ”¾éŸ³é¢‘")
    }
    
    // è®¡ç®—å®é™…çš„å¸§æ•°ï¼šä½¿ç”¨æ­£ç¡®çš„å¸§æ•°è®¡ç®—
    // å¯¹äº32ä½æµ®ç‚¹æ ¼å¼ï¼Œæ¯å¸§4å­—èŠ‚ï¼Œä½†éœ€è¦è€ƒè™‘å£°é“æ•°
    let bytesPerSample = 4 // 32ä½æµ®ç‚¹ = 4å­—èŠ‚
    // æ³¨æ„ï¼šbufferList.mNumberBuffers æ˜¯ç¼“å†²åŒºæ•°é‡ï¼Œä¸æ˜¯å£°é“æ•°
    // å¯¹äºäº¤é”™æ ¼å¼ï¼Œé€šå¸¸åªæœ‰ä¸€ä¸ªç¼“å†²åŒºåŒ…å«æ‰€æœ‰å£°é“æ•°æ®
    let totalSamples = Int(buffer.mDataByteSize) / bytesPerSample
    // å‡è®¾æ˜¯ç«‹ä½“å£°ï¼ˆ2å£°é“ï¼‰ï¼Œæ¯å¸§åŒ…å«2ä¸ªæ ·æœ¬
    let channels = 2 // ä»Process Tapè·å–çš„æ ¼å¼ä¿¡æ¯
    let frameCount = UInt32(totalSamples / channels)
    
    // è®¡ç®—ç”µå¹³
    handler.calculateAndReportLevel(from: bufferList, frameCount: frameCount)
    
    // å†™å…¥éŸ³é¢‘æ•°æ®
    handler.writeAudioData(from: bufferList, frameCount: frameCount)
    
    return noErr
}

// MARK: - AudioCallbackHandler
/// éŸ³é¢‘å›è°ƒå¤„ç†å™¨ - è´Ÿè´£å¤„ç†éŸ³é¢‘æ•°æ®æµå’Œæ–‡ä»¶å†™å…¥
@available(macOS 14.4, *)
class AudioCallbackHandler {
    
    // MARK: - Properties
    let logger = Logger.shared
    private var audioFile: AVAudioFile?
    private var audioToolboxFileManager: AudioToolboxFileManager?
    private var onLevel: ((Float) -> Void)?
    
    // MARK: - Initialization
    
    init() {}
    
    // MARK: - Public Methods
    
    /// è®¾ç½®éŸ³é¢‘æ–‡ä»¶
    func setAudioFile(_ file: AVAudioFile) {
        self.audioFile = file
    }
    
    /// è®¾ç½® AudioToolbox æ–‡ä»¶ç®¡ç†å™¨
    func setAudioToolboxFileManager(_ manager: AudioToolboxFileManager) {
        self.audioToolboxFileManager = manager
        logger.info("ğŸµ AudioCallbackHandler: è®¾ç½® AudioToolbox æ–‡ä»¶ç®¡ç†å™¨")
    }
    
    /// è®¾ç½®ç”µå¹³å›è°ƒ
    func setLevelCallback(_ callback: @escaping (Float) -> Void) {
        self.onLevel = callback
    }
    
    /// åˆ›å»ºéŸ³é¢‘å›è°ƒå‡½æ•°
    func createAudioCallback() -> (AudioDeviceIOProc, UnsafeMutableRawPointer) {
        logger.info("ğŸ§ AudioCallbackHandler: åˆ›å»ºéŸ³é¢‘å›è°ƒå‡½æ•°...")
        // åˆ›å»º self çš„ä¸å®‰å…¨æŒ‡é’ˆï¼Œç”¨äºä¼ é€’ç»™ C å›è°ƒå‡½æ•°
        let selfPointer = Unmanaged.passUnretained(self).toOpaque()
        logger.info("âœ… éŸ³é¢‘å›è°ƒå‡½æ•°åˆ›å»ºæˆåŠŸï¼Œå®¢æˆ·ç«¯æ•°æ®æŒ‡é’ˆ: \(selfPointer)")
        return (globalAudioCallback, selfPointer)
    }
    
    /// åˆ›å»º PCM ç¼“å†²åŒº
    func makePCMBuffer(from bufferList: UnsafePointer<AudioBufferList>, frames: UInt32, asbd: AudioStreamBasicDescription) -> AVAudioPCMBuffer? {
        guard let audioFile = audioFile else { return nil }
        
        let format = audioFile.processingFormat
        guard let pcm = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(frames)) else {
            return nil
        }
        
        pcm.frameLength = AVAudioFrameCount(frames)
        
        let abl = bufferList.pointee
        let channels = Int(asbd.mChannelsPerFrame)
        let bytesPerFrame = Int(asbd.mBytesPerFrame)
        
        guard let src = abl.mBuffers.mData else { return nil }
        
        if let dst = pcm.floatChannelData {
            let frameStride = Int(bytesPerFrame)
            let totalFrames = Int(frames)
            for c in 0..<channels {
                var s = src.assumingMemoryBound(to: Float.self).advanced(by: c)
                var d = dst[c]
                for i in 0..<totalFrames {
                    d[i] = s.pointee
                    s = s.advanced(by: channels)
                }
            }
        } else if let dst = pcm.int16ChannelData {
            // å°†32ä½æµ®ç‚¹æ•°æ®è½¬æ¢ä¸º16ä½æ•´æ•°æ•°æ®
            let frameStride = Int(bytesPerFrame)
            let totalFrames = Int(frames)
            for c in 0..<channels {
                var s = src.assumingMemoryBound(to: Float.self).advanced(by: c)
                var d = dst[c]
                for i in 0..<totalFrames {
                    // å°†æµ®ç‚¹æ•°è½¬æ¢ä¸º16ä½æ•´æ•°ï¼š-1.0 åˆ° 1.0 æ˜ å°„åˆ° -32768 åˆ° 32767
                    let floatValue = s.pointee
                    let int16Value = Int16(max(-1.0, min(1.0, floatValue)) * 32767.0)
                    d[i] = int16Value
                    s = s.advanced(by: channels)
                }
            }
        } else if let dst = pcm.int32ChannelData {
            let frameStride = Int(bytesPerFrame)
            let totalFrames = Int(frames)
            for c in 0..<channels {
                var s = src.assumingMemoryBound(to: Int32.self).advanced(by: c)
                var d = dst[c]
                for i in 0..<totalFrames {
                    d[i] = s.pointee
                    s = s.advanced(by: channels)
                }
            }
        }
        
        return pcm
    }
    
    // MARK: - Private Methods
    
    func calculateAndReportLevel(from bufferList: AudioBufferList, frameCount: UInt32) {
        guard let onLevel = onLevel else { 
            logger.debug("AudioCallbackHandler: æ²¡æœ‰ç”µå¹³å›è°ƒå‡½æ•°")
            return 
        }
        
        let buffer = bufferList.mBuffers
        guard let data = buffer.mData else { 
            logger.debug("AudioCallbackHandler: éŸ³é¢‘æ•°æ®ä¸ºç©º")
            return 
        }
        
        let samples = data.assumingMemoryBound(to: Float.self)
        let sampleCount = Int(buffer.mDataByteSize) / MemoryLayout<Float>.size
        
        logger.debug("AudioCallbackHandler: è®¡ç®—ç”µå¹³ - frameCount: \(frameCount), sampleCount: \(sampleCount), dataSize: \(buffer.mDataByteSize)")
        
        var maxLevel: Float = 0.0
        var rmsLevel: Float = 0.0
        var sumSquares: Float = 0.0
        
        for i in 0..<sampleCount {
            let sample = abs(samples[i])
            if sample > maxLevel {
                maxLevel = sample
            }
            sumSquares += sample * sample
        }
        
        // è®¡ç®— RMS
        if sampleCount > 0 {
            rmsLevel = sqrt(sumSquares / Float(sampleCount))
        }
        
        // è½¬æ¢ä¸º dB
        let maxDB = maxLevel > 0 ? 20 * log10(maxLevel) : -96.0
        let rmsDB = rmsLevel > 0 ? 20 * log10(rmsLevel) : -96.0
        let normalizedLevel = max(0, min(1, (rmsDB + 96) / 96))
        
        logger.debug("AudioCallbackHandler: ç”µå¹³è®¡ç®— - maxLevel: \(maxLevel), rmsLevel: \(rmsLevel), maxDB: \(maxDB), rmsDB: \(rmsDB), normalized: \(normalizedLevel)")
        
        DispatchQueue.main.async {
            onLevel(normalizedLevel)
        }
    }
    
     func writeAudioData(from bufferList: AudioBufferList, frameCount: UInt32) {
        guard frameCount > 0 else { 
            logger.debug("AudioCallbackHandler: è·³è¿‡å†™å…¥ - frameCount: \(frameCount)")
            return 
        }
        
        // ä¼˜å…ˆä½¿ç”¨ AudioToolbox æ–‡ä»¶ç®¡ç†å™¨
        if let audioToolboxManager = audioToolboxFileManager {
            do {
                try audioToolboxManager.writeAudioData(bufferList, frameCount: frameCount)
                logger.debug("AudioCallbackHandler: ä½¿ç”¨ AudioToolbox æˆåŠŸå†™å…¥ \(frameCount) å¸§éŸ³é¢‘æ•°æ®")
                return
            } catch {
                logger.error("AudioCallbackHandler: AudioToolbox å†™å…¥å¤±è´¥: \(error.localizedDescription)")
                // å¦‚æœ AudioToolbox å¤±è´¥ï¼Œå›é€€åˆ° AVAudioFile
            }
        }
        
        // å›é€€åˆ° AVAudioFileï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        guard let audioFile = audioFile else { 
            logger.debug("AudioCallbackHandler: è·³è¿‡å†™å…¥ - æ²¡æœ‰å¯ç”¨çš„æ–‡ä»¶ç®¡ç†å™¨")
            return 
        }
        
        logger.debug("AudioCallbackHandler: ä½¿ç”¨ AVAudioFile å‡†å¤‡å†™å…¥ \(frameCount) å¸§éŸ³é¢‘æ•°æ®")
        
        // åˆ›å»ºPCMç¼“å†²åŒºï¼Œç¡®ä¿å¤§å°è¶³å¤Ÿ
        guard let pcmBuffer = AVAudioPCMBuffer(pcmFormat: audioFile.processingFormat, frameCapacity: frameCount) else {
            logger.error("AudioCallbackHandler: æ— æ³•åˆ›å»ºPCMç¼“å†²åŒº")
            return
        }
        
        // è°ƒè¯•ï¼šæ£€æŸ¥æ ¼å¼åŒ¹é…
        logger.debug("AudioCallbackHandler: PCMç¼“å†²åŒºæ ¼å¼ - å£°é“æ•°: \(audioFile.processingFormat.channelCount), é‡‡æ ·ç‡: \(audioFile.processingFormat.sampleRate), äº¤é”™: \(audioFile.processingFormat.isInterleaved)")
        
        // å¤åˆ¶bufferListä¸­çš„æ•°æ®åˆ°PCMç¼“å†²åŒº
        // å¤„ç†äº¤é”™å’Œéäº¤é”™æ ¼å¼
        if bufferList.mNumberBuffers == 1 {
            // äº¤é”™æ ¼å¼ï¼šæ‰€æœ‰å£°é“æ•°æ®åœ¨ä¸€ä¸ªbufferä¸­
            let buffer = bufferList.mBuffers
            logger.debug("AudioCallbackHandler: æ£€æŸ¥bufferæ•°æ® - mData: \(buffer.mData != nil), mDataByteSize: \(buffer.mDataByteSize)")
            guard buffer.mData != nil && buffer.mDataByteSize > 0 else { 
                logger.warning("AudioCallbackHandler: bufferæ•°æ®æ— æ•ˆï¼Œè·³è¿‡å†™å…¥")
                return 
            }
            
            // æ ¹æ®è¾“å‡ºæ ¼å¼é€‰æ‹©æ­£ç¡®çš„æ•°æ®ç±»å‹
            logger.debug("AudioCallbackHandler: æ£€æŸ¥PCMç¼“å†²åŒºæ•°æ®ç±»å‹ - int16ChannelData: \(pcmBuffer.int16ChannelData != nil), floatChannelData: \(pcmBuffer.floatChannelData != nil)")
            if let dstChannelData = pcmBuffer.floatChannelData {
                // è¾“å‡ºæ ¼å¼æ˜¯32ä½æµ®ç‚¹
                logger.debug("AudioCallbackHandler: è¿›å…¥floatChannelDataåˆ†æ”¯")
                let srcData = buffer.mData!.assumingMemoryBound(to: Float.self)
                let outputChannels = Int(audioFile.processingFormat.channelCount)
                let frameCountInt = Int(frameCount)
                
                // è®¡ç®—è¾“å…¥æ•°æ®çš„å®é™…å£°é“æ•°
                let totalSamples = Int(buffer.mDataByteSize) / MemoryLayout<Float>.size
                let inputChannels = totalSamples / frameCountInt
                
                logger.debug("AudioCallbackHandler: æ•°æ®è§£æ - æ€»æ ·æœ¬: \(totalSamples), å¸§æ•°: \(frameCountInt), è¾“å…¥å£°é“: \(inputChannels), è¾“å‡ºå£°é“: \(outputChannels)")
                
                if inputChannels == 1 && outputChannels == 2 {
                    // å•å£°é“è½¬ç«‹ä½“å£°ï¼šå°†å•å£°é“æ•°æ®å¤åˆ¶åˆ°å·¦å³å£°é“
                    for frame in 0..<frameCountInt {
                        if frame < totalSamples {
                            let monoValue = srcData[frame]
                            dstChannelData[0][frame] = monoValue  // å·¦å£°é“
                            dstChannelData[1][frame] = monoValue  // å³å£°é“
                        }
                    }
                    logger.debug("AudioCallbackHandler: å•å£°é“è½¬ç«‹ä½“å£°å®Œæˆï¼Œå¤åˆ¶äº† \(frameCountInt) å¸§")
                } else if inputChannels == outputChannels {
                    // å£°é“æ•°åŒ¹é…ï¼šç›´æ¥å¤åˆ¶äº¤é”™æ•°æ®
                    for frame in 0..<frameCountInt {
                        for channel in 0..<outputChannels {
                            let srcIndex = frame * inputChannels + channel
                            if srcIndex < totalSamples {
                                dstChannelData[channel][frame] = srcData[srcIndex]
                            }
                        }
                    }
                    logger.debug("AudioCallbackHandler: ç›´æ¥å¤åˆ¶å®Œæˆï¼Œ\(inputChannels)å£°é“åˆ°\(outputChannels)å£°é“")
                } else {
                    // å…¶ä»–æƒ…å†µï¼šå°è¯•äº¤é”™æ ¼å¼è§£æ
                    let channelDataSize = min(totalSamples / inputChannels, frameCountInt)
                    for frame in 0..<channelDataSize {
                        for channel in 0..<min(outputChannels, inputChannels) {
                            let srcIndex = frame * inputChannels + channel
                            if srcIndex < totalSamples {
                                dstChannelData[channel][frame] = srcData[srcIndex]
                            }
                        }
                    }
                    logger.debug("AudioCallbackHandler: äº¤é”™æ ¼å¼è§£æå®Œæˆï¼Œå¤„ç†äº† \(channelDataSize) å¸§")
                }
                
                // è®¾ç½®å®é™…å†™å…¥çš„å¸§æ•°
                pcmBuffer.frameLength = UInt32(frameCountInt)
            } else if let dstChannelData = pcmBuffer.int16ChannelData {
                // è¾“å‡ºæ ¼å¼æ˜¯16ä½æ•´æ•°
                let srcData = buffer.mData!.assumingMemoryBound(to: Float.self)
                let outputChannels = Int(audioFile.processingFormat.channelCount)
                let frameCountInt = Int(frameCount)
                
                // è®¡ç®—è¾“å…¥æ•°æ®çš„å®é™…å£°é“æ•°
                let totalSamples = Int(buffer.mDataByteSize) / MemoryLayout<Float>.size
                let inputChannels = totalSamples / frameCountInt
                
                logger.debug("AudioCallbackHandler: æ•°æ®è§£æ - æ€»æ ·æœ¬: \(totalSamples), å¸§æ•°: \(frameCountInt), è¾“å…¥å£°é“: \(inputChannels), è¾“å‡ºå£°é“: \(outputChannels)")
                
                if inputChannels == 1 && outputChannels == 2 {
                    // å•å£°é“è½¬ç«‹ä½“å£°ï¼šå°†å•å£°é“æ•°æ®å¤åˆ¶åˆ°å·¦å³å£°é“
                    for frame in 0..<frameCountInt {
                        if frame < totalSamples {
                            let monoValue = Int16(srcData[frame] * 32767.0) // è½¬æ¢ä¸º16ä½æ•´æ•°
                            dstChannelData[0][frame] = monoValue  // å·¦å£°é“
                            dstChannelData[1][frame] = monoValue  // å³å£°é“
                        }
                    }
                    logger.debug("AudioCallbackHandler: å•å£°é“è½¬ç«‹ä½“å£°å®Œæˆï¼Œå¤åˆ¶äº† \(frameCountInt) å¸§")
                } else if inputChannels == outputChannels {
                    // å£°é“æ•°åŒ¹é…ï¼šç›´æ¥å¤åˆ¶äº¤é”™æ•°æ®
                    for frame in 0..<frameCountInt {
                        for channel in 0..<outputChannels {
                            let srcIndex = frame * inputChannels + channel
                            if srcIndex < totalSamples {
                                dstChannelData[channel][frame] = Int16(srcData[srcIndex] * 32767.0) // è½¬æ¢ä¸º16ä½æ•´æ•°
                            }
                        }
                    }
                    logger.debug("AudioCallbackHandler: ç›´æ¥å¤åˆ¶å®Œæˆï¼Œ\(inputChannels)å£°é“åˆ°\(outputChannels)å£°é“")
                } else {
                    // å…¶ä»–æƒ…å†µï¼šå°è¯•äº¤é”™æ ¼å¼è§£æ
                    let channelDataSize = min(totalSamples / inputChannels, frameCountInt)
                    for frame in 0..<channelDataSize {
                        for channel in 0..<min(outputChannels, inputChannels) {
                            let srcIndex = frame * inputChannels + channel
                            if srcIndex < totalSamples {
                                dstChannelData[channel][frame] = Int16(srcData[srcIndex] * 32767.0) // è½¬æ¢ä¸º16ä½æ•´æ•°
                            }
                        }
                    }
                    logger.debug("AudioCallbackHandler: äº¤é”™æ ¼å¼è§£æå®Œæˆï¼Œå¤„ç†äº† \(channelDataSize) å¸§")
                }
                
                // è®¾ç½®å®é™…å†™å…¥çš„å¸§æ•°
                pcmBuffer.frameLength = UInt32(frameCountInt)
            }
        } else {
            // éäº¤é”™æ ¼å¼ï¼šæ¯ä¸ªå£°é“æœ‰ç‹¬ç«‹çš„buffer
            logger.debug("AudioCallbackHandler: å¤„ç†éäº¤é”™æ ¼å¼ï¼Œbufferæ•°é‡: \(bufferList.mNumberBuffers)")
            
            // æš‚æ—¶è·³è¿‡éäº¤é”™æ ¼å¼çš„å¤„ç†ï¼Œè®°å½•è­¦å‘Š
            logger.warning("AudioCallbackHandler: éäº¤é”™æ ¼å¼æš‚ä¸æ”¯æŒï¼Œè·³è¿‡æ•°æ®å†™å…¥")
            return
        }
        
        do {
            // ç¡®ä¿frameLengthæ­£ç¡®è®¾ç½®
            if pcmBuffer.frameLength == 0 {
                logger.warning("AudioCallbackHandler: PCMç¼“å†²åŒºå¸§æ•°ä¸º0ï¼Œè·³è¿‡å†™å…¥")
                return
            }
            
            // è°ƒè¯•ï¼šæ£€æŸ¥å†™å…¥å‰çš„çŠ¶æ€
            logger.debug("AudioCallbackHandler: å†™å…¥å‰æ£€æŸ¥ - frameLength: \(pcmBuffer.frameLength), frameCapacity: \(pcmBuffer.frameCapacity)")
            
            try audioFile.write(from: pcmBuffer)
            logger.debug("AudioCallbackHandler: ä½¿ç”¨ AVAudioFile æˆåŠŸå†™å…¥ \(pcmBuffer.frameLength) å¸§éŸ³é¢‘æ•°æ®")
        } catch {
            logger.error("AudioCallbackHandler: AVAudioFile å†™å…¥å¤±è´¥: \(error.localizedDescription)")
        }
    }
}